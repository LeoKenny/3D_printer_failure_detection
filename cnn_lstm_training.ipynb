{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling1D,\n",
    "    TimeDistributed,\n",
    "    Dropout\n",
    ")\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(folder)/'processed_labeled_image_data.npy', 'rb') as f:\n",
    "    x_data = np.load(f)\n",
    "\n",
    "with open(Path(folder)/'processed_labeled_image_result.npy', 'rb') as f:\n",
    "    y_data = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_categorical = to_categorical(y_data,num_classes=np.unique(y_data).shape[0])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data,y_data_categorical,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y_data_categorical)\n",
    "\n",
    "x_val, _, y_val, _ = train_test_split(x_val,y_val,\n",
    "                                        test_size=0.34,\n",
    "                                        random_state=42,\n",
    "                                        stratify=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_lstm = Sequential([\n",
    "    Input((None, 44, 4)),\n",
    "    TimeDistributed(\n",
    "        Sequential([\n",
    "            Conv1D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Flatten(),\n",
    "        ]),\n",
    "    ),\n",
    "    LSTM(50, kernel_initializer=GlorotUniform(), activation='relu', return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(50, kernel_initializer=GlorotUniform(), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax'),\n",
    "])\n",
    "model_cnn_lstm.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"categorical_accuracy\",\"accuracy\"])\n",
    "model_cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=folder/f'best_{model_name}_model.keras',       # Filepath to save the model\n",
    "    monitor='val_accuracy',            # Monitor validation accuracy\n",
    "    save_best_only=True,               # Save only the best model\n",
    "    save_weights_only=False,           # Save the full model (architecture + weights)\n",
    "    mode='max',                        # Save when the monitored quantity is maximized\n",
    "    verbose=1                          # Verbosity mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_cnn_lstm.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(folder)/f'training_history_{model_name}.json', 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn_lstm.predict(x_train)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_train_classes = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Calculate precision and recall for multi-class classification\n",
    "precision = precision_score(y_train_classes, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_train_classes, y_pred_classes, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn_lstm.predict(x_val)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate precision and recall for multi-class classification\n",
    "precision = precision_score(y_test_classes, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_test_classes, y_pred_classes, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_bidirectional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_bi = Sequential([\n",
    "    Input((None, 44, 4)),\n",
    "    TimeDistributed(\n",
    "        Sequential([\n",
    "            Conv1D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Flatten(),\n",
    "        ]),\n",
    "    ),\n",
    "    Bidirectional(LSTM(100, kernel_initializer=GlorotUniform(), activation='relu')),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax'),\n",
    "])\n",
    "model_cnn_bi.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"categorical_accuracy\",\"accuracy\"])\n",
    "model_cnn_bi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=f'best_{model_name}_model.keras',       # Filepath to save the model\n",
    "    monitor='val_accuracy',            # Monitor validation accuracy\n",
    "    save_best_only=True,               # Save only the best model\n",
    "    save_weights_only=False,           # Save the full model (architecture + weights)\n",
    "    mode='max',                        # Save when the monitored quantity is maximized\n",
    "    verbose=1                          # Verbosity mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model_cnn_bi.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(folder)/f'training_history_{model_name}.json', 'w') as f:\n",
    "    json.dump(history2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn_bi.predict(x_train)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_train_classes = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Calculate precision and recall for multi-class classification\n",
    "precision = precision_score(y_train_classes, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_train_classes, y_pred_classes, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cnn_bi.predict(x_val)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_val_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate precision and recall for multi-class classification\n",
    "precision = precision_score(y_val_classes, y_pred_classes, average='macro')\n",
    "recall = recall_score(y_val_classes, y_pred_classes, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "failure_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
